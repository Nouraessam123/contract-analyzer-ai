import streamlit as st
import os
import docx
import shutil
from langchain_community.document_loaders import PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_groq import ChatGroq
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from dotenv import load_dotenv

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="AI Legal Auditor", layout="wide")
load_dotenv()

# ØªØ­Ø³ÙŠÙ† Ø´ÙƒÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.markdown("""
    <style>
    .stApp { background-color: #f8f9fa; }
    h1, h2, h3 { color: #1e3d59; font-family: 'Arial'; }
    .stButton>button { width: 100%; border-radius: 8px; background-color: #1e3d59; color: white; height: 3em; font-weight: bold; }
    .stButton>button:hover { background-color: #ffc107; color: #1e3d59; border: 1px solid #1e3d59; }
    .stAlert { border-radius: 10px; }
    </style>
    """, unsafe_allow_html=True)

# Ø¯Ø§Ù„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙˆÙˆØ±Ø¯
def read_docx(file_path):
    doc = docx.Document(file_path)
    text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
    return [Document(page_content=text, metadata={"source": "uploaded_docx"})]

@st.cache_resource
def load_models():
    embeddings = HuggingFaceEmbeddings(model_name="./my_model")
    llm = ChatGroq(
        temperature=0, 
        api_key=os.getenv("GROQ_API_KEY"), 
        model_name="llama-3.3-70b-versatile"
    )
    return embeddings, llm

embeddings, llm = load_models()

st.title("âš–ï¸ Ù…Ù†ØµØ© ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ©")
st.write("Ø­Ù„Ù„ Ø¹Ù‚ÙˆØ¯Ùƒ Ø¨Ø¯Ù‚Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©ØŒ Ø§ÙƒØªØ´Ù Ø§Ù„Ø«ØºØ±Ø§ØªØŒ ÙˆØ§Ø¶Ù…Ù† Ø­Ù‚ÙˆÙ‚Ùƒ Ø¨Ù…ÙŠØ²Ø§Ù† Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ.")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ø¹Ù‚Ø¯ (PDF Ø£Ùˆ DOCX)", type=["pdf", "docx"])

if uploaded_file:
    file_ext = uploaded_file.name.split('.')[-1].lower()
    temp_path = f"temp_ui.{file_ext}"
    
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯..."):
            if file_ext == "pdf":
                loader = PyPDFLoader(temp_path)
                docs = loader.load()
            else:
                docs = read_docx(temp_path)

        full_content = " ".join([d.page_content for d in docs])
        
        # --- ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø¹Ù‚Ø¯ (Validation) ---
        legal_keywords = ["Ø¹Ù‚Ø¯", "Ø¨Ù†Ø¯", "Ø·Ø±Ù", "Ø§Ù„ØªØ²Ø§Ù…", "Ø§ØªÙØ§Ù‚", "Ù‚Ø§Ù†ÙˆÙ†", "ØµÙ„Ø§Ø­ÙŠØ©", "Ø§Ø®ØªØµØ§Øµ", "contract", "agreement"]
        is_legal = any(word in full_content.lower() for word in legal_keywords)

        if not is_legal or len(full_content.strip()) < 150:
            st.error("âš ï¸ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…Ø±ÙÙ‚ Ù„Ø§ ÙŠØ¨Ø¯Ùˆ Ø¹Ù‚Ø¯Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ Ù…Ø¹ØªÙ…Ø¯Ø§Ù‹. ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ù†ÙˆØ¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ø¶Ø­Ø©.")
            st.stop()
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø§Ù„Ø±Ù‚Ù…ÙŠ
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
        splits = text_splitter.split_documents(docs)
        vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
        
        # Ø²ÙŠØ§Ø¯Ø© k Ù„Ù€ 6 Ù„Ø¶Ù…Ø§Ù† ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø®Ø§Ø·Ø±
        retriever = vectorstore.as_retriever(search_kwargs={"k": 6})

        # Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø°ÙƒÙŠØ©
        def run_legal_task(task_instruction, use_table=False):
            relevant_docs = retriever.invoke(task_instruction)
            context = "\n\n".join([doc.page_content for doc in relevant_docs])
            
            table_info = "Ø¨Ø±Ø¬Ø§Ø¡ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø´ÙƒÙ„ Ø¬Ø¯ÙˆÙ„ Markdown Ù…Ù†Ø¸Ù…." if use_table else ""

            # Ø§Ù„Ù€ Prompt Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ Ø§Ù„Ù…Ø·ÙˆØ±
            full_prompt = f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØµØ±ÙŠ Ø®Ø¨ÙŠØ± ÙˆØ´Ø¯ÙŠØ¯ Ø§Ù„Ø°ÙƒØ§Ø¡. 
            Ù…Ù‡Ù…ØªÙƒ: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±ÙÙ‚ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¯Ù‚Ø© ÙˆÙ‚ÙˆØ© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.

            Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„:
            1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø±ÙÙ‚ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±ØŒ Ø§Ù„Ø«ØºØ±Ø§ØªØŒ ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª.
            2. ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© (Ù…Ø«Ù„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±)ØŒ Ù‚Ù… Ø¨Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„ØªØ¨Ø¹Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø§Ù„Ø¹Ù‚Ø¯ ÙˆØ§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ.
            3. Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ø¨Ù†Ø¯Ø§Ù‹ ØºØ§Ù…Ø¶Ø§Ù‹ Ø£Ùˆ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù†Ø§Ù‚ØµØ© (Ù…Ø«Ù„ ØºÙŠØ§Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø£Ùˆ Ø´Ø±ÙˆØ· Ø§Ù„ÙØ³Ø®)ØŒ ÙˆØ¶Ø­ Ø°Ù„Ùƒ ÙÙˆØ±Ø§Ù‹ ÙƒØ®Ø·Ø± Ù…Ø­ØªÙ…Ù„.
            4. Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ ÙÙ‚Ø·ØŒ ÙˆØ¨Ø£Ø³Ù„ÙˆØ¨ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø±ØµÙŠÙ†.
            5. Ù…Ù…Ù†ÙˆØ¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ Ù„ØºØ© ØºÙŠØ± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.

            Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:
            {context}

            Ø§Ù„Ù…Ù‡Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {task_instruction}
            {table_info}

            Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ©:"""
            
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ..."):
                response = llm.invoke(full_prompt)
                return response.content

        # Ø¹Ø±Ø¶ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
        st.success("âœ… ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ù†Ø¬Ø§Ø­. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚.")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("ğŸ“ Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù‚Ø¯"):
                res = run_legal_task("Ù„Ø®Øµ Ø£Ù‡Ù… Ø¨Ù†ÙˆØ¯ Ø§Ù„Ø¹Ù‚Ø¯ (Ø§Ù„Ø£Ø·Ø±Ø§ÙØŒ Ø§Ù„Ù‚ÙŠÙ…Ø©ØŒ Ø§Ù„Ù…Ø¯Ø©ØŒ ÙˆØ·Ø¨ÙŠØ¹Ø© Ø§Ù„Ø¹Ù…Ù„).", True)
                st.markdown(res)
        with col2:
            if st.button("ğŸš¨ ÙƒØ´Ù Ø§Ù„Ù…Ø®Ø§Ø·Ø±"):
                res = run_legal_task("Ø§Ø³ØªØ®Ø±Ø¬ Ø£ÙŠ Ø«ØºØ±Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø£Ùˆ Ù…Ø®Ø§Ø·Ø± Ù…Ø­ØªÙ…Ù„Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù‚Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨Ù†ÙˆØ¯ Ø§Ù„ÙØ³Ø® ÙˆØ§Ù„ØªØ¹ÙˆÙŠØ¶Ø§Øª.")
                st.warning(res)
        with col3:
            if st.button("ğŸ’° Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª"):
                res = run_legal_task("Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©ØŒ Ø·Ø±Ù‚ Ø§Ù„Ø¯ÙØ¹ØŒ ÙˆØ§Ù„Ø¬Ø²Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©ØŸ", True)
                st.info(res)

        st.divider()
        st.subheader("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ")
        user_query = st.text_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø£ÙŠ Ø¨Ù†Ø¯ Ù…Ø­Ø¯Ø¯ (Ù…Ø«Ù„Ø§Ù‹: Ù…Ø§ Ù‡Ùˆ Ù…ÙˆÙ‚Ù Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø«Ø§Ù†ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©ØŸ)")
        if user_query:
            answer = run_legal_task(user_query)
            st.chat_message("assistant").write(answer)

    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)
else:
    st.info("ğŸ’¡ **Ù†ØµÙŠØ­Ø©:** Ø§Ø±ÙØ¹ Ø¹Ù‚Ø¯Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ Ø¨ØµÙŠØºØ© PDF Ø£Ùˆ Word Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ù‚ ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ù†ÙˆÙ†ÙŠ.")